{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains three sections of code which can be used to do the following tasks:\n",
    "1. Use the OpenAI API to convert Markdown text into structured JSON\n",
    "2. Convert the output of the above task (a JSON file) into a CSV file for further processing\n",
    "3. Use the OpenAI API to convert Markdown text directory into a CSV/xlsx spreadsheet file\n",
    "\n",
    "These tasks are part of a data processing pipeline for transforming historic texts into machine-readable data. To read more about how this pipeline was used in practice, see our datasets created from the [1871 Rivers Pollution Committee Report]('https://github.com/congruence-engine/connecting-environmental-data/tree/main/datasets/1871%20Rivers%20Pollution%20Commission'). \n",
    "\n",
    "These code snippets were created with the help of Chat GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Markdown to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(client, input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as file:\n",
    "        text_content = file.read()\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant with excellent skills in parsing structured data.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Output information in JSON format according to the response format, using the markdown text supplied. Each entry should have three fields: 'business_name', 'business_type', 'address', and 'reply'. 'reply' should include the full text shown under each business - do not leave anything out. DO NOT include additional fields. DO NOT return in a codeblock. Do not include any explanations or extra text. Ensure that the JSON is properly formatted and valid. Do not include any comments or notes. Markdown Text: {text_content}\"}\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\n",
    "                    \"name\": \"businesses_info\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"businesses\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"business_name\": {\"type\": \"string\"},\n",
    "                                        \"business_type\": {\"type\": \"string\"},\n",
    "                                        \"address\": {\"type\": \"string\"},\n",
    "                                        \"reply\": {\"type\": \"string\"}\n",
    "                                    },\n",
    "                                    \"required\": [\"business_name\", \"business_type\", \"address\", \"reply\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"businesses\"],\n",
    "                        \"additionalProperties\": False\n",
    "                    },\n",
    "                    \"strict\": True\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(json.loads(completion.choices[0].message.content), json_file, indent=2)\n",
    "\n",
    "        return f\"Processed {os.path.basename(input_path)} -> {os.path.basename(output_path)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error processing {os.path.basename(input_path)}: {str(e)}\"\n",
    "\n",
    "def process_txt_files(input_dir, output_dir, max_workers=5):\n",
    "    client = OpenAI()\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    tasks = []\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.json\")\n",
    "            tasks.append((input_path, output_path))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(process_file, client, input_path, output_path): input_path \n",
    "                          for input_path, output_path in tasks}\n",
    "        \n",
    "        for future in as_completed(future_to_file):\n",
    "            print(future.result())\n",
    "\n",
    "# Usage\n",
    "input_directory = 'input/directory' # Replace with your inpput directory\n",
    "output_directory = 'output/directory' # Replace with your output directory\n",
    "\n",
    "process_txt_files(input_directory, output_directory, max_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def json_to_csv(json_file_path, output_csv):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    businesses = data.get('businesses', [])\n",
    "\n",
    "    if businesses:\n",
    "        fieldnames = businesses[0].keys()\n",
    "\n",
    "        with open(output_csv, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            \n",
    "            for business in businesses:\n",
    "                writer.writerow(business)\n",
    "\n",
    "        print(f\"CSV file '{output_csv}' has been created successfully.\")\n",
    "    else:\n",
    "        print(\"No businesses found in the JSON file.\")\n",
    "\n",
    "json_file_path = 'json/file/path/file.json'  # Replace with your JSON file path\n",
    "output_csv = 'output/file/path/file.csv'    # Replace with your CSV file path\n",
    "\n",
    "json_to_csv(json_file_path, output_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Markdown to CSV/xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def extract_information(text):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant with excellent skills in parsing structured data.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"From the markdown text provided, output the text in csv format with three columns: 'company_name', 'address', and 'answers_to_questions'. DO NOT include additional columns. Use pipes (|) as separators instead of commas. DO NOT return in a codeblock. Just return the text in csv format, ensuring that no text except column headers is left out. Skip any pipes (|) that appear in the source text. Markdown Text: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    return response\n",
    "\n",
    "df = pd.DataFrame(columns=['company_name', 'address', 'answers_to_questions'])\n",
    "\n",
    "input_directory = 'inoput/directory'  # Replace with your directory path\n",
    "\n",
    "for filename in sorted(os.listdir(input_directory)):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(input_directory, filename)\n",
    "        print(f\"Processing file: {filename}\")\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        \n",
    "        try:\n",
    "            csv_text = extract_information(text)\n",
    "            temp_df = pd.read_csv(StringIO(csv_text), sep='|')\n",
    "            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "output_excel_path = 'output/path/file.xlsx'  # Replace with your output path. In this case we have used .xlsx\n",
    "df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to '{output_excel_path}'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
