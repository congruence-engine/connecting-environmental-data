{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process PDF to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Converting PDF to images with DPI={300}...\")\n",
    "images = convert_from_path(\"/Users/gladyscallow/Library/CloudStorage/OneDrive-UniversityofCambridge/JESUS/CONGRUENCE ENGINE/RIVER POLLUTION/OCR EXTRACTION/part_ii_bradford/resized/test.pdf\", dpi=300, fmt='jpeg')\n",
    "total_pages = len(images)\n",
    "digits = len(str(total_pages))\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    image_path = os.path.join(\"/Users/gladyscallow/Library/CloudStorage/OneDrive-UniversityofCambridge/JESUS/CONGRUENCE ENGINE/RIVER POLLUTION/OCR EXTRACTION/part_ii_bradford/resized/images\", f\"Page_{str(i+1).zfill(digits)}.jpeg\")\n",
    "    image.save(image_path, \"JPEG\")\n",
    "    print(f\"Page {i+1} saved as image: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def process_images_in_directory(input_directory, output_directory):\n",
    "    input_dir = Path(input_directory)\n",
    "    output_dir = Path(output_directory)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all image files in the directory\n",
    "    images = sorted(input_dir.glob('*.*'), key=lambda x: x.stem)\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.tiff', '.bmp', '.gif']\n",
    "\n",
    "    for image_path in images:\n",
    "        if image_path.suffix.lower() not in image_extensions:\n",
    "            print(f\"Skipping non-image file: {image_path.name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {image_path.name}...\")\n",
    "\n",
    "        # Encode the image to base64\n",
    "        base64_image = encode_image_to_base64(str(image_path))\n",
    "\n",
    "        # Prepare the messages payload\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Return the markdown text output from this page in a PDF using formatting to match the structure of the page as closely as you can. Only output the markdown and nothing else. Do not explain the output, just return it. Do not use a single # for a heading. All headings will start with ## or ###. Convert tables to markdown tables. DO NOT return in a code block. Just return the raw text in markdown format.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",  # Use the correct model name\n",
    "                messages=messages,\n",
    "                max_tokens=1500,\n",
    "                temperature=0.1,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling OpenAI API for image {image_path.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        markdown_content = response.choices[0].message.content\n",
    "\n",
    "        output_file = output_dir / (image_path.stem + \".txt\")\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(markdown_content)\n",
    "            print(f\"Saved markdown for {image_path.name} to {output_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving markdown for image {image_path.name}: {e}\")\n",
    "\n",
    "\n",
    "input_directory = 'input directory'      # Replace with your input directory path\n",
    "output_directory = 'output directory'    # Replace with your desired output directory path\n",
    "\n",
    "process_images_in_directory(input_directory, output_directory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
